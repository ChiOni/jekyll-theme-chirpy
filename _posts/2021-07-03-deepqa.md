---
title: Question Answering Using Deep Learning (ICSEE 2019)
date: 2021-07-03 00:00:00 +0800
categories: [Paper Review, Language]
tags: [qa]
seo:
  date_modified: 2020-07-03 22:27:38 +0900
---





인터넷에서 [구글 검색의 원리](https://www.google.com/intl/ko/search/howsearchworks/algorithms/#:~:text=%EA%B2%80%EC%83%89%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%98%20%EC%9B%90%EB%A6%AC&text=%EA%B2%80%EC%83%89%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%80%20%EA%B0%80%EC%9E%A5%20%EC%9C%A0%EC%9A%A9%ED%95%9C,%EC%84%B1%EA%B2%A9%EC%97%90%20%EB%94%B0%EB%9D%BC%20%EB%8B%AC%EB%9D%BC%EC%A7%91%EB%8B%88%EB%8B%A4.)라는 신기한 글을 읽었다.  

구글에서 검색 알고리즘에 어떤 것들을 반영하여, 어떻게 사용하고 있는지에 대한 개요 같은 글이다.  

요약하자면 소비자의 검색(질문)을 구글에 있는 최적의 자료들로 대답하는 여러 방법론이 있는 것 같았다.  

충분히 흥미로워서 관련하여 `qa deep learning`이라는 키워드로 검색하여 논문을 하나 읽어보았다.  

엄청 찾아본 것은 아니라 확실하지는 않지만 위의 주제로 수천개의 cited를 받은 표준은 아직 없는 것 같다.  

<br/>

## <b> Abstract</b>

논문에서는 QA Task를 `bAbI` 라는 데이터셋에 적용해본다고 한다. 처음 보는 데이터라 찾아보았다.  

<br/>

<b>bAbI Dataset</b>

- [Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks](https://paperswithcode.com/paper/towards-ai-complete-question-answering-a-set)
- Facebook AI Reasearch에서 인간과 대화할 수 있는 시스템 개발을 목표로 오픈한 데이터이다.
- 총 20가지의 Task로 분류되어 있다. 사실 연결, 추론, 유도 등등등
- 각 데이터는 (문맥 - 질문 - 답변)으로 구성되어 있다.
- 이렇게 문맥안에 답변이 있는 것을 closed QA dataset이라고 부른다. (open QA dataset도 있나보다)
- (EX)
  - 문맥: Mary moved to the bathroom
  - 질문: Where is Mary?
  - 답변: Bathroom  

<br/>

## <b>Introduction</b>

QA는 NLP에서 전통적으로 중요한 과제라고 한다.  

과거에 IBM Watson과 같은 시스템들은 `conventional linguistically-based NLP techniques`를 따랐지만,  

당연하게도 최근의 것들은 DNN을 이용하여 문제를 풀어내고 있다고 한다.  

논문에서는 여러 DNN 기법들을 응용하여 여러 task에서 비교해봤고,  

특히 Attention 기반의 모델에서 우수하고 빠른 성능을 얻을 수 있었다고 한다.  

<br/>

## <b>Approach</b>

논문에서는 keras를 사용한 두 개의 베이스 라인, 그리고 자체적으로 개발한 attention 기반의 두 모델.  

총 4가지 모델 구조를 사용하여 실험을 진행했다.  

<br/>

#### <b> 1. GRU baseline</b>

  <img src="/assets/img/pr/deepqa/deepqaone.jpg"> 

위 이미지에서 Stroy에 해당하는 것이 문맥이고, Question은 물론 질문이다.  



(읽는중)